import json
import cv2
from skimage.metrics import structural_similarity as ssim
import shutil
import pandas as pd

from core.process_img_script import process_img
from core.command_operator import *
from core.LLm_history import Global_LLm_history, language, gpt_choice
from core.screenshot_translator import ScreenshotTranslator
from core.LLM_api import use_LLM
from core.help_seq_getter import help_get_flag, help_seq_get
from core.Config import *
import logging
logging.disable(logging.DEBUG)
logging.disable(logging.WARNING)

taskdf = pd.read_excel(TaskTable_PATH, keep_default_na=False)
input_ProcessImgModel = True
if input_ProcessImgModel:
    # å¯¼å…¥æ¨¡å‹ å¼€æœºä»…ä¸€æ¬¡å³å¯
    import core.import_models as import_models
    model_ver, model_det, model_cls, preprocess, ocr = import_models.import_all_models \
        (alg,
            # model_path_yolo='pt_model/yolo_s_best.pt',
            accurate_ocr = accurate_ocr,
            model_path_yolo='pt_model/yolo_mdl.pt',
            model_path_vins_dir='pt_model/yolo_vins_',
            model_ver='14',
            model_path_vins_file='_mdl.pt',
            model_path_cls='pt_model/clip_mdl.pth'
            )


def are_images_similar(save_path_old, save_path_new, threshold=0.90, threshold_roi=0.97, roi=None): #å›¾ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼ 
    
    img1 = cv2.imread(save_path_old)# è¯»å–å›¾ç‰‡
    img2 = cv2.imread(save_path_new)

    # Check if dimensions are different
    if img1.shape != img2.shape:
        shutil.copy(save_path_new, save_path_old)
        return False  # è¡¨ç¤ºå›¾ç‰‡æ›´æ–°äº†
    
    if roi is not None:
        x, y, w, h = roi
        img1_roi = img1[y:y + h, x:x + w]
        img2_roi = img2[y:y + h, x:x + w]
        gray_img1_roi = cv2.cvtColor(img1_roi, cv2.COLOR_BGR2GRAY)
        gray_img2_roi = cv2.cvtColor(img2_roi, cv2.COLOR_BGR2GRAY)
        similarity_index_roi, _ = ssim(gray_img1_roi, gray_img2_roi, full=True)
    else:
        similarity_index_roi = 1

    gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
  
    similarity_index, _ = ssim(gray_img1, gray_img2, full=True)
    shutil.copy(save_path_new, save_path_old)
    return similarity_index > threshold and similarity_index_roi > threshold_roi

def eleLoc_2_roi(element_location): #element_location = {'left': 42, 'right': 838, 'top': 2036, 'bottom': 2185}
    roi = (
        element_location['left'] - 10,
        element_location['top'] - 10 ,
        element_location['right'] - element_location['left'] + 30,
        element_location['bottom'] - element_location['top'] + 30
    )
    return roi

def client_main():
    
    # åˆå§‹åŒ–å‡†å¤‡
    global task_str
    global tapped_button_str
    global invalid_button_str
    global taped_element_content
    global taped_element_roi
    global default_reason
    
    shutil.copy(save_path_default, save_path_old)
    first_flag = True
    task_str = ""
    default_reason = ""
    invalid_button_str = [""]
    taped_element_content = ""
    taped_element_roi = None
    tapped_button_str = ["ï¼Œç°åœ¨å·²ç»è¿›è¡Œäº†çš„æ“ä½œæœ‰"]


    print("\n*--------------------------------- START --------------------------------------*")

    message = "Qï¼š" + input("ğŸ¥°: Hi, I'm VisionTasker. What can I do for you~")  # Go to Alipay to analyze my spending in annual

    # message = "Qï¼š" + message
    if message.startswith("Q"):  # å¤„ç†ä»¥ "ä»»åŠ¡ä¸º:" å¼€å¤´çš„æ¶ˆæ¯
        task_str = str(message)
        task_str = task_str.split('Qï¼š')[-1]
        print("ğŸ‘‚ User:", task_str)
        response = "ğŸ§: OK, let me help you ğŸ‘Œ"
        print(response)

        # è‹¥æ˜¯å†æ¬¡è¾“å…¥mï¼Œåˆ™é‡ç½®æ­¤æ¬¡ä»»åŠ¡çš„æ‰€æœ‰ä¿¡æ¯
        if len(tapped_button_str) > 1:
            print("Enter the task content again, and the operation record is available, reset the task, please return to the initial interface")
            shutil.copy(save_path_default, save_path_old)
            default_reason = ""
            invalid_button_str = [""]
            taped_element_content = ""
            taped_element_roi = None
            tapped_button_str = ["ï¼Œç°åœ¨å·²ç»è¿›è¡Œäº†çš„æ“ä½œæœ‰"]
            Global_LLm_history.__init__(language, gpt_choice)
            # æ ¹æ®ä»»åŠ¡å†…å®¹è·å–å¸®åŠ©æ–‡æ¡£ä¿¡æ¯
        if not help_get_flag:
            help_str = ''
        else:
            help_question, help_content = help_seq_get(task_str)
            help_str = f"æ­¤æ¬¡ä»»åŠ¡çš„å¸®åŠ©æ–‡æ¡£ä¿¡æ¯ï¼š{help_question} {help_content}" if help_question and help_content else ''
            print(help_str)

    else:
        # å¤„ç†å…¶ä»–æ¶ˆæ¯
        print("Received a different message")

    
    try:
        while True:
            time.sleep(5)
            if not first_flag:
                print('ğŸ§: Move on!')
            first_flag = False
            print("\n*---------------------- SCREEN UNDERSTANDING ---------------------------*")
            # æˆªå›¾ or é•¿æˆªå›¾
            if longscreenshot_flag:
                capture_longscreenshot(save_path_new)
            else:
                capture_screenshot(save_path_new)

            print('ğŸ§: Hmmm, I can watch your screen now...')
            # æ ¹æ®å›¾ç‰‡æ˜¯å¦æ›´æ–°ï¼Œåˆ¤æ–­ä¸Šæ¬¡ç‚¹å‡»çš„æ§ä»¶çš„å¯ç‚¹å‡»æ€§ï¼ˆæ²¡æ›´æ–°å°±æ˜¯ä¸å¯ç‚¹å‡»ï¼‰
            screenshot_update_flag = not(are_images_similar(save_path_old, save_path_new, roi = taped_element_roi))
            if (not screenshot_update_flag) and taped_element_content != '' and not default_reason: # å›¾ç‰‡æ²¡æ›´æ–° + ä¸æ˜¯åœ¨å‘é€äº†mä¹‹å + ä¸æ˜¯è¿‡ç¨‹ä¸­å‡ºç°äº† ç•Œé¢ä¸å­˜åœ¨è¯¥å…ƒç´ æˆ–å›ç­”æ ¼å¼ä¸å¯¹
                tapped_button_str.pop()  # åˆ å»ä¸Šæ¬¡ç‚¹å‡»çš„æ§ä»¶ä¿¡æ¯
                # åˆ å»llmä¸Šæ¬¡çš„inputå’Œoutputä¿¡æ¯
                Global_LLm_history.clear_previous_one_record()
                Global_LLm_history.clear_previous_one_record()

                invalid_button_str.append(f"['{taped_element_content}']")  # è®°å½•è¿™ä¸ªæ— æ•ˆçš„button
            else:
                invalid_button_str = ['']  # é‡ç½®æ— æ•ˆæ§ä»¶åˆ—è¡¨
            print('ğŸ§: OK, let me take a closer look......')
            result_js = process_img(label_path_dir, save_path_old, output_root, layout_json_dir, high_conf_flag,
                        alg, clean_save, plot_show, ocr_save_flag, model_ver, model_det, 
                        model_cls, preprocess, pd_free_ocr=ocr, ocr_only=ocr_output_only, lang=language, accurate_ocr=accurate_ocr)


            # å­˜å‚¨jsonæ–‡ä»¶
            json.dump(result_js, open(SCREEN_jSON_PATH, 'w', encoding='utf-8'), indent=4, ensure_ascii=False)

            # å°†å±å¹•ä¿¡æ¯jsonæ–‡ä»¶ è½¬æ¢æˆ æ˜“é˜…è¯»çš„å­—ç¬¦ä¸²
            print('ğŸ§: Haha, time for LLM!')
            print("\n*--------------------------- TASK PLANNING -----------------------------*")

            ScreenshotTranslatorTest = ScreenshotTranslator(SCREEN_jSON_PATH)
            humanword = ScreenshotTranslatorTest.json2humanword()

            # æç¤ºllmçš„æ³¨æ„äº‹é¡¹
            if len(invalid_button_str) == 1:  # =1ä»£è¡¨åˆå§‹ï¼Œå³æ²¡æœ‰æ— æ•ˆæ§ä»¶
                invalid_button_string = 'ã€‚'
                if default_reason.startswith("ç•Œé¢ä¸­ä¸å­˜åœ¨"):
                    invalid_button_string = f"ã€‚æ³¨æ„{default_reason}ã€‚"
                    default_reason = ""
            else: #å­˜åœ¨æ— æ•ˆæ§ä»¶ï¼Œå³ä¸å¯ç‚¹å‡»çš„æ§ä»¶
                invalid_button_string = ''.join(map(str, invalid_button_str)) #æ— æ•ˆæ§ä»¶æé†’
                invalid_button_string = f"ã€‚æ³¨æ„æ§ä»¶{invalid_button_string}ä¸å¯ç‚¹å‡»ã€‚"
                if default_reason.startswith("ç•Œé¢ä¸­ä¸å­˜åœ¨"):
                    invalid_button_string = f"ã€‚æ³¨æ„æ§ä»¶{invalid_button_string}ä¸å¯ç‚¹å‡»,{default_reason}ã€‚"
                    default_reason = ""

            # æ•´åˆè¦é€å…¥llmçš„ä¿¡æ¯
            if len(tapped_button_str) == 1: # =1ä»£è¡¨åˆå§‹ï¼Œå³æ²¡æœ‰ç‚¹å‡»è¿‡æ§ä»¶
                object_message_humanword = f'Qï¼š{task_str}ï¼Œ{help_str}å½“å‰ç•Œé¢æœ‰ä»¥ä¸‹æŒ‰é’®ï¼š{humanword}{invalid_button_string}'
            else:
                tapped_button_string = ''.join(map(str, tapped_button_str))
                object_message_humanword = f'Qï¼š{task_str}{tapped_button_string}ï¼Œ{help_str}å½“å‰ç•Œé¢æœ‰ä»¥ä¸‹æŒ‰é’®ï¼š{humanword}{invalid_button_string}'
            print(object_message_humanword)

            object_message_humanword = json.dumps(object_message_humanword)
            order_list = use_LLM(gpt_choice, object_message_humanword)


            for order in order_list:
                if order['action'] != 'default':  # llm è¿”å›æœ‰æ•ˆå‘½ä»¤
                    # è‹¥æ­¤æ¬¡ç‚¹å‡»çš„æ§ä»¶ä¸ä¸Šæ¬¡ç‚¹å‡»æ§ä»¶ä¸åŒï¼Œæ­¤æ¬¡æœ‰æ•ˆ
                    if taped_element_content != order['button_content']:
                        taped_element_content = order['button_content'] # ç‚¹å‡»çš„æ§ä»¶å†…å®¹
                        taped_element_roi = eleLoc_2_roi(order['element_location']) # ç‚¹å‡»çš„ä½ç½®

                        # è®°å½•æ“ä½œå†å²
                        if order['action'] == 'keyboard_input':
                            input_text_content = order['data']['input_text']
                            tapped_button_str.append(f'ï¼ˆåœ¨è¾“å…¥æ¡†:[{repr(taped_element_content)}]è¾“å…¥äº†{repr(input_text_content)}å¹¶å›è½¦ï¼‰')
                        elif order['action'] == 'tap':
                            tapped_button_str.append(f'ï¼ˆç‚¹å‡»[{repr(taped_element_content)}]ï¼‰')
                else:
                    default_reason = order['reason']
                    print("Please send the screenshot again and GPT will regenerate the operation command")

            response = json.dumps(order_list, ensure_ascii=False)  # è½¬æ¢order_listä¸ºJSONæ ¼å¼

            print(f"Execute: {response}")  # å¤„ç†æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤
            response = eval(response)


            if isinstance(response, str):
                # print("response æ˜¯å­—ç¬¦ä¸²ç±»å‹")
                pass
            elif isinstance(response, list):
                order_list = response
                operator(order_list)  # ä¼ é€’æœåŠ¡å™¨è¿”å›çš„order_listä¸­çš„æ¯ä¸ªæ“ä½œ
                print("\n*---------------------------- âˆš ONE STEP COMPLETED ----------------------------*\n\n\n")

            else:
                print("response æ˜¯å…¶ä»–ç±»å‹")
                
        
    finally:
        print(f"client_mainå‘ç”Ÿå¼‚å¸¸")


if __name__ == "__main__":

    client_main()
